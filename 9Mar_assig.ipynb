{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa61c82-b718-4c24-b0cc-4232c1e7379e",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191ea26-e4ac-4cee-8c04-30c44820d94d",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions used to describe the probability distribution of a random variable.\n",
    "\n",
    "Probability Mass Function (PMF): The PMF is applicable to discrete random variables. It gives the probability of each possible outcome occurring. The PMF assigns a probability value to each specific value of the random variable. Example: Consider rolling a fair six-sided die. The PMF for this scenario would assign a probability value of 1/6 to each outcome (1, 2, 3, 4, 5, or 6) because each face of the die has an equal chance of occurring.\n",
    "\n",
    "Probability Density Function (PDF): The PDF is used for continuous random variables. It represents the likelihood of a random variable falling within a specific range of values. Unlike the PMF, the PDF does not give the probability of individual values; instead, it provides the relative likelihood of values within a range. Example: Suppose we have a continuous random variable that represents the height of individuals in a population. The PDF for this variable would describe the likelihood of finding individuals within a specific height range. For instance, it might indicate that the probability density is higher for heights between 160 cm and 170 cm, suggesting that individuals within that range are more likely to be found in the population.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables, providing the probability of each individual outcome. The PDF is used for continuous random variables, describing the likelihood of values falling within specific ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7fd81-fd02-4b0a-8b06-c830e480a4cf",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c63c8-7863-4508-bf56-397934d1af2c",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that gives the probability that a random variable takes on a value less than or equal to a given value. It provides cumulative information about the probability distribution.\n",
    "\n",
    "Example: Let's consider a continuous random variable representing the time it takes for a customer to complete a task at a service center. The CDF for this variable would give the probability that a customer's task time is less than or equal to a specific value.\n",
    "\n",
    "Suppose the CDF at time t=5 minutes is 0.8. This means that there is an 80% probability that a customer's task time is less than or equal to 5 minutes. The CDF can be interpreted as the area under the probability density curve up to a given value.\n",
    "\n",
    "The CDF is used for several reasons:\n",
    "\n",
    "Probability calculation: The CDF allows us to calculate the probability of a random variable falling within a certain range by subtracting the CDF values at the lower and upper limits of the range.\n",
    "\n",
    "Percentile determination: The CDF helps determine percentiles or quantiles of a distribution. For example, the value of the random variable at which the CDF reaches 0.5 represents the median.\n",
    "\n",
    "Distribution comparison: CDFs can be used to compare and analyze different probability distributions. By plotting multiple CDFs on the same graph, we can visually assess differences in their shapes, locations of percentiles, or probabilities at specific values.\n",
    "\n",
    "Estimation of parameters: CDFs are employed in statistical estimation techniques, such as maximum likelihood estimation, to estimate the parameters of a distribution that best fit observed data.\n",
    "\n",
    "In summary, the Cumulative Density Function (CDF) provides cumulative information about the probability distribution of a random variable, giving the probability that the variable takes on a value less than or equal to a given value. It is useful for probability calculations, percentile determination, distribution comparison, and parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d9286-c5a3-4af7-a964-2aa41cad83ef",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f6546-8c3d-4df1-bac5-126d4a6fc518",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is widely used as a model in various fields where data tend to exhibit a bell-shaped pattern. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights and weights: In many populations, the distribution of heights and weights often follows a normal distribution.\n",
    "\n",
    "Test scores: When analyzing test scores of a large group of individuals, the normal distribution is often assumed as a reasonable approximation.\n",
    "\n",
    "Errors in measurement: Random errors in measurements, such as in scientific experiments or data collection, are often assumed to be normally distributed.\n",
    "\n",
    "Financial markets: Changes in stock prices or returns on investments are commonly modeled using the normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: mean (μ) and standard deviation (σ).\n",
    "\n",
    "The mean (μ) represents the central tendency of the distribution and indicates where the peak of the bell-shaped curve is located. The standard deviation (σ) determines the spread or dispersion of the distribution. A larger standard deviation results in a wider and flatter curve, indicating greater variability in the data. By adjusting the mean and standard deviation, the shape, location, and scale of the normal distribution can be modified. The mean shifts the distribution horizontally, while the standard deviation controls its spread. Changes in these parameters can create distributions that are more peaked or flatter, narrower or wider, and shifted to the left or right.\n",
    "\n",
    "In summary, the normal distribution is often used as a model in situations where data exhibit a bell-shaped pattern. The mean parameter determines the center of the distribution, while the standard deviation parameter influences the spread. Adjusting these parameters allows for modeling different variations of the normal distribution to fit specific data patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816853ab-bea1-45e1-80a0-22a7fe025d3b",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d0466-ff2c-4b7a-8429-535f75a1b2b7",
   "metadata": {},
   "source": [
    "The Normal Distribution, also known as the Gaussian distribution, holds significant importance in statistics and data analysis due to its widespread applicability and several key properties. Some of the reasons why the Normal Distribution is important are:\n",
    "\n",
    "Central Limit Theorem: The Normal Distribution is a fundamental concept in the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables tends to follow a Normal Distribution, regardless of the underlying distribution of the variables themselves. This theorem allows for powerful statistical inference and estimation techniques.\n",
    "\n",
    "Data Modeling: Many real-life phenomena naturally follow a Normal Distribution. Examples include physical measurements like height and weight of individuals in a population, errors in measurements, test scores, and financial market returns. By assuming a Normal Distribution, we can simplify the modeling process and make predictions or draw inferences from the data.\n",
    "\n",
    "Statistical Analysis: The Normal Distribution provides a solid foundation for various statistical methods and hypothesis testing. Numerous statistical techniques, such as Z-tests, t-tests, and chi-square tests, rely on the assumptions of Normality to draw accurate conclusions from data.\n",
    "\n",
    "Parameter Estimation: In many statistical models, estimating the parameters of a distribution is a crucial step. The Normal Distribution is often used as a reference or default distribution for estimation procedures, such as maximum likelihood estimation and least squares regression, due to its mathematical properties and simplicity.\n",
    "\n",
    "Real-life examples of phenomena that can be modeled by the Normal Distribution include:\n",
    "\n",
    "Heights and weights of individuals in a population. IQ scores of a large sample of people. Errors in scientific measurements or experimental data. Blood pressure readings in a population. Test scores in a standardized exam. Time taken to complete a task by a group of people. In summary, the Normal Distribution is important due to its applicability in various fields, its role in the Central Limit Theorem, and its usefulness in data modeling, statistical analysis, and parameter estimation. It is encountered in numerous real-life examples where data exhibit a bell-shaped pattern, allowing for effective analysis and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2161f6-ab7b-4707-a0e5-095e11cd1220",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1633af3-51f0-4bcf-8fe6-c9046cfbc7de",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a probability distribution that models a random experiment with two possible outcomes: success and failure. It is named after the Swiss mathematician Jacob Bernoulli. In the context of the Bernoulli distribution:\n",
    "\n",
    "\"Success\" is typically denoted as 1.\n",
    "\"Failure\" is typically denoted as 0.\n",
    "The distribution is characterized by a single parameter, usually denoted as \"p,\" which represents the probability of success in a single trial.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is as follows:\n",
    "\n",
    "P(X = 1) = p (probability of success)\n",
    "P(X = 0) = 1 - p (probability of failure)\n",
    "\n",
    "Here's an example to illustrate the Bernoulli distribution:\n",
    "\n",
    "Example:\n",
    "Consider a single coin toss, where \"Heads\" is considered a success (1) and \"Tails\" is considered a failure (0). The probability of getting a \"Heads\" in a fair coin toss is p = 0.5. This situation can be modeled using a Bernoulli distribution with p = 0.5.\n",
    "\n",
    "Now, let's address the difference between the Bernoulli distribution and the Binomial distribution:\n",
    "\n",
    "1. Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: The Bernoulli distribution models a single trial or experiment with two possible outcomes, typically labeled as 1 (success) and 0 (failure).\n",
    "\n",
    "Binomial Distribution: The Binomial distribution models a series of independent and identical trials (experiments), each with two possible outcomes (success or failure). It represents the number of successes (k) that occur in a fixed number of trials (n).\n",
    "\n",
    "2. Parameters:\n",
    "\n",
    "Bernoulli Distribution: The Bernoulli distribution is parameterized by a single probability, often denoted as \"p,\" which represents the probability of success in a single trial.\n",
    "\n",
    "Binomial Distribution: The Binomial distribution is parameterized by two values: the number of trials (n) and the probability of success in each trial (p).\n",
    "\n",
    "3. Probability Mass Function (PMF):\n",
    "\n",
    "Bernoulli Distribution: The Bernoulli distribution has a PMF that assigns probabilities to two discrete values: 1 (success) and 0 (failure).\n",
    "\n",
    "Binomial Distribution: The Binomial distribution has a PMF that gives the probability of obtaining k successes in n trials, and it involves more complex combinatorial calculations.\n",
    "\n",
    "4. Use Cases:\n",
    "\n",
    "Bernoulli Distribution: The Bernoulli distribution is often used to model a single trial of a binary event, such as flipping a coin (success = heads, failure = tails), where you are interested in the probability of success in that single trial.\n",
    "\n",
    "Binomial Distribution: The Binomial distribution is used to model scenarios where you want to know the probability of getting a specific number of successes (k) in a fixed number of independent trials (n) with the same probability of success (p) in each trial. Examples include the number of successful free throws in a fixed number of attempts or the number of defective items in a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b05307-485a-4286-b471-9803cb8d3d5e",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04561b-fedd-4bc1-8bb9-01d7476114f7",
   "metadata": {},
   "source": [
    "The probability that a randomly selected observation from a dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 can be calculated using the following formula:\n",
    "\n",
    "P(X > 60) = 1 - P(X <= 60)\n",
    "\n",
    "The probability that a randomly selected observation will be less than or equal to 60 can be calculated using the normal distribution table. The normal distribution table gives the probability that a standard normal variable will be less than or equal to a certain value. A standard normal variable has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "To use the normal distribution table, we first need to convert our observation of 60 to a standard normal variable. This can be done using the following formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "Z is the standard normal variable X is the observation μ is the mean of the dataset σ is the standard deviation of the dataset In this case, Z = (60 - 50) / 10 = 1.00.\n",
    "\n",
    "Now that we have converted our observation to a standard normal variable, we can look up the probability of a standard normal variable being less than or equal to 1.00 in the normal distribution table. The probability that a standard normal variable will be less than or equal to 1.00 is 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from a dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 is 1 - 0.8413 = 0.1587.\n",
    "\n",
    "In other words, there is a 15.87% chance that a randomly selected observation from this dataset will be greater than 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2a3ff4-0014-42a3-b259-aaf20da88d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an observation being greater than 60 is: 0.15866\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "observed_value = 60\n",
    "\n",
    "# calculate the z-score\n",
    "z_score = (observed_value - mean) / std_dev\n",
    "\n",
    "# calculate the probability using the cumulative distribution function (cdf)\n",
    "probability = 1 - norm.cdf(z_score)\n",
    "\n",
    "print(\"The probability of an observation being greater than 60 is:\", round(probability,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d9116-6870-4d75-b338-b1a2645b403f",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c013db-93d8-4ea1-abb0-d4d477d95680",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution where every possible outcome has an equal chance of occurring. This means that the values of a random variable are spread evenly over a given interval or range.\n",
    "A classic example of a uniform distribution is the roll of a fair die. The die has six faces, each labeled with a number from 1 to 6, and all the faces are equally likely to come up when the die is rolled. Therefore, the probability of each outcome is 1/6, and this distribution is called a discrete uniform distribution.\n",
    "Lottery or raffle draws - If a lottery or raffle is conducted fairly, where each ticket has an equal chance of being drawn, the distribution of winning ticket numbers follows a discrete uniform distribution.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's say you have a six-sided fair die (like a standard die used in board games) where the faces are numbered from 1 to 6. The probability of rolling any one of these numbers is the same because each outcome is equally likely. This is an example of a discrete uniform distribution.\n",
    "\n",
    "In this case, you can represent the uniform distribution as follows:\n",
    "\n",
    "Probability of rolling a 1: P(X = 1) = 1/6\n",
    "Probability of rolling a 2: P(X = 2) = 1/6\n",
    "Probability of rolling a 3: P(X = 3) = 1/6\n",
    "Probability of rolling a 4: P(X = 4) = 1/6\n",
    "Probability of rolling a 5: P(X = 5) = 1/6\n",
    "Probability of rolling a 6: P(X = 6) = 1/6\n",
    "In this example, the probabilities of getting each possible outcome (1 through 6) are all equal, which conforms to the characteristics of a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e72464-7db1-469f-be79-252b98865584",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5add3-7754-4a83-bc39-2a7ffe311f0a",
   "metadata": {},
   "source": [
    "A z-score is a statistical measure that tells you how many standard deviations a specific data point is away from the mean. A z-score is calculated by subtracting the mean from the data point and then dividing by the standard deviation.\n",
    "\n",
    "Z-scores are important because they allow you to compare data points from different distributions. For example, if you have a set of data on the heights of people in the United States and a set of data on the heights of people in China, you can't directly compare the heights of people in the two groups because the distributions of heights are different. However, if you convert the heights of people in each group to z-scores, you can then compare the z-scores directly.\n",
    "\n",
    "Z-scores are also used to determine how likely it is that a specific data point will occur. For example, if you know that the z-score for a certain height is 2.0, you can use a z-table to find out that the probability of a person being that height or taller is 97.7%.\n",
    "\n",
    "Here is the formula for calculating a z-score :\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "z is the z-score x is the data point μ is the mean of the distribution σ is the standard deviation of the distribution Here is an example of how to calculate a z-score:\n",
    "\n",
    "Suppose you have a set of data on the heights of people in the United States. The mean height is 68 inches and the standard deviation is 3 inches. If you have a data point of 72 inches, the z-score would be calculated as follows:\n",
    "\n",
    "z = (72 - 68) / 3 = 1.33\n",
    "\n",
    "This means that the data point of 72 inches is 1.33 standard deviations above the mean.\n",
    "\n",
    "Z-scores are a powerful tool that can be used to compare data points from different distributions and to determine the likelihood of a specific data point occurring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3462b2-31cc-4de3-b488-c3ce152bb68d",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0fdfa-2c66-465b-96df-f984ea3a74ec",
   "metadata": {},
   "source": [
    "The central limit theorem (CLT) is a theorem in probability theory that states that, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed, regardless of the underlying distribution.\n",
    "\n",
    "The CLT is a fundamental theorem in statistics and has wide-ranging applications. It is used in hypothesis testing, confidence interval estimation, and regression analysis.\n",
    "\n",
    "The CLT is based on the idea that the average of a large number of random variables will be closer to the population mean than any individual random variable. This is because the average of a large number of random variables will tend to cancel out the effects of any outliers or extreme values.\n",
    "\n",
    "The CLT also states that the standard deviation of the average of a large number of random variables will be smaller than the standard deviation of any individual random variable. This is because the average of a large number of random variables will tend to smooth out the fluctuations in the individual random variables.\n",
    "\n",
    "The CLT is a powerful tool that can be used to make inferences about populations based on samples. For example, if you want to know the average height of all people in the United States, you could take a random sample of people and calculate the average height of the sample. If the sample is large enough, the CLT tells you that the average height of the sample will be approximately normally distributed. This means that you can use a z-table to find the probability that the average height of the sample is within a certain range of the population mean.\n",
    "\n",
    "The CLT is also used in many other areas of statistics, such as hypothesis testing, confidence intervals, and regression analysis.\n",
    "\n",
    "Here are some of the significance of the Central Limit Theorem:\n",
    "\n",
    "It allows us to make inferences about populations based on samples. It can be used to calculate probabilities of events occurring. It can be used to estimate population parameters. It is used in many different areas of statistics, such as hypothesis testing, confidence intervals, and regression analysis. The CLT is a powerful tool that can be used to make sense of data. It is essential for understanding many statistical concepts and techniques.\n",
    "\n",
    "Here are some examples of how the CLT is used in practice:\n",
    "\n",
    "In hypothesis testing, the CLT is used to calculate the p-value of a test statistic. The p-value is the probability of obtaining a test statistic at least as extreme as the one that was observed, assuming that the null hypothesis is true. In confidence interval estimation, the CLT is used to calculate the confidence interval for a population parameter. The confidence interval is a range of values that is likely to contain the population parameter. In regression analysis, the CLT is used to calculate the standard errors of the regression coefficients. The standard errors of the regression coefficients are used to test the significance of the coefficients and to construct confidence intervals for the predicted values. The CLT is a powerful tool that can be used to make inferences about populations based on samples. It is essential for understanding many statistical concepts and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37c2cb-b4c3-4b95-a754-a98ae0cb8fe5",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75072e6d-94a3-4f2d-b2ed-6a9e587c5909",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) states that if we take a large number of samples from a population, the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution. The CLT has four main assumptions:\n",
    "\n",
    "Random sampling: The samples must be randomly selected from the population. This means that each member of the population has an equal chance of being selected.\n",
    "\n",
    "Independent samples: The samples must be independent of each other. This means that the selection of one sample does not affect the selection of any other sample.\n",
    "\n",
    "Sufficient sample size: The sample size must be large enough for the CLT to apply. The exact sample size required depends on the shape of the population distribution.\n",
    "\n",
    "Continuous variable: The variable being measured must be continuous. This means that the variable can take on any value within a given range.\n",
    "\n",
    "If these assumptions are met, then the CLT can be used to make inferences about the population mean based on the sample mean. For example, we can use the CLT to construct confidence intervals for the population mean or to test hypotheses about the population mean.\n",
    "\n",
    "It is important to note that the CLT is a statistical theorem, and like all statistical theorems, it is based on probability. This means that there is a chance that the CLT will not apply in a particular situation. However, the CLT is a very powerful tool, and it can be used to make accurate inferences about the population mean in a wide variety of situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
